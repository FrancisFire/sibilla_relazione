
\section{Descrizione dell'infrastruttura}
L'architettura alla base delle comunicazioni tra i vari nodi della libreria è di natura \textbf{master/slave}.
Più specificatamente, le simulazioni da eseguire sono sottomesse da parte di un \textbf{client} che si connette ad un \textbf{server master} disponibile pubblicamente in rete, da cui vengono provengono anche i risultati delle simulazioni. 
All'interno della rete locale al master sono quindi presenti i \textbf{server slave} che rappresentano le unità di elaborazione delle simulazioni. Questi server non sono disponibili pubblicamente in rete e interagiscono con il master per poter ricevere nuove simulazioni da eseguire e per poter restituire i risultati di tali simulazioni.

\subsection{Client}
La logica di funzionamento di un \textbf{client} è contenuta interamente nella classe \texttt{ClientSimulationEnvironment}, le cui istanze devono essere incluse in tutte le classi di avvio di un client.
Nella definizione della classe di avvio di un client server è necessario includere l'istanziazione di un oggetto della classe \texttt{ModelDefinition}, rappresentante il modello della simulazione che verrà sottomesso per essere elaborato, e parametri relativi alla simulazione quali il numero delle repliche e la deadline.

Alla sua creazione, l'istanza di \texttt{clientSimulationEnvironment} cercherà di contattare tramite la rete un server master utilizzando i parametri definiti all'avvio, quali porta, indirizzo IP e tipo di comunicazione basata su TCP. 
Durante questa fase vengono trasmessi al server master i byte contenuti nel file compilato .class relativo alla classe che implementa \texttt{ModelDefinition}, istanziata all'avvio del client.
Il caricamento di queste informazioni nel server master risulta fondamentale per poter gestire correttamente i dati e i parametri relativi alla simulazione che sono trasmessi dal client successivamente alla prima fase.

L'invio di questi dati coincide con la sottomissione effettiva della simulazione al server master. 
Tutte le comunicazioni successive a questa fase riguardano la ricezione dei risultati da parte del server master e la chiusura della comunicazione sia lato client che lato server master.

\subsection{Server master}

La classe \texttt{MasterServerSimulationEnvironment} contiene tutta la logica di un \textbf{server master}, qui vengono avviati i servizi che deve fornire un server master, cioè il discovery dei server slave remoti e la gestione delle simulazioni richieste dai \textbf{client}. Inoltre i due servizi sono collegati e due oggetti \texttt{NetworkInfo} diversi, dove il primo è inerente alle informazioni di rete legate al servizio di discovery, mentre il secondo contiene le informazioni di rete legate al servizio di esecuzione delle simulazioni.

Il servizio di \textbf{discovery} dei server slave remoti è gestito da due thread separati. Il primo si occupa del \textbf{broadcast} su \textbf{tutte le reti locali} connesse al server master, per mezzo di un \texttt{UDPNetworkManager}, dell'oggetto \texttt{NetworkInfo} relativo alle informazioni di rete locali per il servizio di discovery. Il secondo thread si occupa invece di ascoltare in rete i messaggi inviati dai server slave e di aggiornare la lista dei server slave collegati di conseguenza.

Il servizio di gestione delle simulazioni si occupa invece di creare un nuovo \texttt{SimulationEnvironment} quando un \textbf{client} richiede l'esecuzione di una simulazione che utilizza un nuovo \texttt{NetworkSimulationManager}, a cui viene passato in input un \texttt{SimulationState}. Il \texttt{SimulationState} in questione contiene tutti i dati necessari per eseguire il \textbf{bilanciamento} delle simulazioni tra i vari server slave, tra cui un set di oggetti \texttt{SlaveState}, ognuno dei quali si riferisce ad uno dei server slave connessi.

In particolare il \textbf{bilanciamento} delle simulazioni tra i vari server slave viene eseguito all'interno della classe \texttt{NetworkSimulationManager}, che, in seguito all'esecuzione della prima \textbf{task} inviata ad un server slave e delle successive, chiamerà il metodo \texttt{update} all'interno dello \texttt{SlaveState} corrispondente al server slave che ha eseguito la task. All'interno di tale metodo, in base al numero di tasks eseguite ed al tempo impiegato, verranno aggiornati i parametri che stabiliscono il numero di task che il server slave può eseguire (\texttt{expectedTasks}) e quelli che stabiliscono il timeout, cioè il tempo oltre il quale l'esecuzione di una task da parte di un server slave può essere dichiarata fallita e si può effettuare la rischedulazione di tali task (\texttt{sampleRTT}, \texttt{estimatedRTT} e \texttt{devRTT}).

Più in dettaglio, l'algoritmo utilizzato per il bilanciamento delle task è molto simile a quello per il \textbf{controllo della congestione in TCP}. Abbiamo infatti un incremento esponenziale del numero di task eseguibili dai server slave, dove, in seguito ad un eventuale \textbf{timeout}, il numero dei task eseguibili viene dimezzato. L'unica differenza è la presenza di una \textbf{soglia} fissa, oltre la quale il numero dei task eseguibili non viene più duplicato, ma viene incrementato di una unità, tale \textbf{soglia} è infatti calcolata dinamicamente nel caso di TCP. Il tempo di \textbf{timeout} viene calcolato invece in base a parametri calcolati dal \textbf{Round Trip Time} tra l'invio del task da parte del server master e la ricezione dei risultati da parte del server slave (\texttt{estimatedRTT} e \texttt{devRTT}).

\subsection{Server slave}
La classe alla base del funzionamento di un \textbf{server slave} è \texttt{DiscoverableBasicSimulationServer}, estensione della classe \texttt{BasicSimulationServer}.
La classe \texttt{BasicSimulationServer} è stata rivista per poter implementare il nuovo protocollo di comunicazione con i server master ma la logica è rimasta la medesima:
le istanze di tale classe sono infatti forniti di due istanze di \texttt{ExecutorService} basati su \texttt{CachedThreadPool} per poter gestire, rispettivamente, le connessioni in ingresso da parte di server master
e per gestire in maniera efficiente i task di simulazione sottomessi sfruttando le capacità di \textbf{multithreading} del server slave.
Nella corrente implementazione di \texttt{BasicSimulationServer} è inoltre presente la gestione della comunicazione con i server master per poter ricevere da questi e caricare in memoria i byte dei file .class associati
alle simulazioni da eseguire e, successivamente, anche i parametri e i dati di tali simulazioni, oltre che per poter inviare ai server master i risultati delle simulazioni richieste una volta che la loro esecuzione è terminata.
Tra le funzionalità presenti nella classe si annoverano anche la possibilità di chiudere la connessione con i server master che lo richiedono, nel caso ideale dopo aver ricevuto i risultati delle simulazioni sottomesse,
e di rispondere ai messaggi di ping che i server master potrebbero inviare in caso sia stato rilevato un timeout. 

Il comportamento aggiuntivo introdotto tramite la classe \texttt{DiscoverableBasicSimulationServer} si focalizza sulla possibilità per un server slave di essere individuato nella propria rete locale da tutti i server master
presenti all'interno della medesima rete. Ogni server slave riceve infatti periodicamente \textbf{messaggi di discovery} inviati in modalità broadcast dai server master presenti, che contengono l'oggetto \texttt{NetworkInfo} con le informazioni riguardo l'\textbf{indirizzo IP}, la \textbf{porta} e l'\texttt{UPDNetworkManagerType} usati per il discovery da parte del server master. Lo slave risponde a tali messaggi inviando l'oggetto \texttt{NetworkInfo} contenente le informazioni di rete del server che eseguirà le simulazioni. In questo modo il singolo server slave
permette di risultare visibile ai server master che, alla successiva interazione da parte di client, lo contatteranno per poter sottomettere nuove simulazioni.
Nell'attuale implementazione, i server slave rispondono ad ogni messaggio di broadcast inviato dai server master presenti nella loro rete. Non conoscendo a priori lo stato del server master e quali server slave sono già stati individuati
tale implementazione permette agli slave di essere sempre visibili per poter ricevere nuove simulazioni da eseguire.